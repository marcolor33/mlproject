{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction #\n",
    "\n",
    "In this project, we try to predict video game sales from different features such as genre, publishers and critic score.\n",
    "By trying different training model, we try to find the best model for sale prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score :-3.86165165838e+15\n",
      "mean_absolute_error :5465554.63252\n",
      "median_absolute_error :0.242153632785\n",
      "mean_absolute_percentage_error :2565835351.01\n",
      "median_absolute_percentage_error :77.0958015872\n",
      "Decision tree with depth 6\n",
      "r2_score :0.180266015023\n",
      "mean_absolute_error :0.319192947168\n",
      "median_absolute_error :0.164293610422\n",
      "mean_absolute_error :216.50025767\n",
      "median_absolute_percentage_error :26.9806495169\n",
      "RBF Kernel\n",
      "r2_score :0.0838527977828\n",
      "mean mean_absolute_error :0.395314410669\n",
      "median_absolute_error :0.210548375567\n",
      "mean_absolute_percentage_error :415.707459601\n",
      "median_absolute_percentage_error :37.8029388689\n",
      "Poly Kernel\n",
      "r2_score :0.214718042346\n",
      "mean_absolute_error :0.258928042061\n",
      "median_absolute_error :0.104047361415\n",
      "mean_absolute_error :205.655972632\n",
      "median_absolute_percentage_error :16.9266284649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor\n",
      "r2_score :-1.44472385596e+19\n",
      "mean_absolute_error :3365163380.89\n",
      "median_absolute_error :2669242213.01\n",
      "mean_absolute_error :3.5798067476e+12\n",
      "median_absolute_percentage_error :550427378388.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, median_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statistics\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def median_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = statistics.median(y_true), statistics.median(y_pred)\n",
    "    return abs((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "# Loading data\n",
    "csv_path = \"data\\Video_Games_Sales_as_at_22_Dec_2016.csv\"\n",
    "\n",
    "# Read csv\n",
    "df = pd.read_csv(csv_path)\n",
    "# print(df.head())\n",
    "\n",
    "# using dummy coding to expand the features\n",
    "df2 = pd.get_dummies(df, columns=['Platform', 'Genre', 'Publisher', 'Developer'])\n",
    "# df2 = df\n",
    "# print(df2.head())\n",
    "\n",
    "# Drop row which has no critic score (NaN)\n",
    "df3 = df2[(df2.Critic_Score.notnull())]\n",
    "# print(df3.head())\n",
    "\n",
    "\n",
    "# shuffle and dropped unused features\n",
    "df3 = shuffle(df3)\n",
    "drop_column = ['Name', 'Year_of_Release', 'User_Score', 'User_Count']\n",
    "df4 = df3.drop(drop_column, 1)\n",
    "# print(df4.head())\n",
    "# print(df4.shape)\n",
    "\n",
    "# standardization of values\n",
    "scaler = StandardScaler()\n",
    "df4[['Critic_Score', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']] = scaler.fit_transform(df4[['Critic_Score', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']])\n",
    "\n",
    "# print(df4.head())\n",
    "\n",
    "# Predict the global sales\n",
    "y = df4['Global_Sales']\n",
    "X = df4.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales', 'Rating'], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n",
    "\n",
    "# Model 1: LinearRegression\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "# print(regr.score(X_test, y_test))\n",
    "y_predict = regr.predict(X_test)\n",
    "print(\"r2_score :\" + str(r2_score(y_test, y_predict)))\n",
    "print(\"mean_absolute_error :\" + str(mean_absolute_error(y_test, y_predict)))\n",
    "print(\"median_absolute_error :\" + str(median_absolute_error(y_test, y_predict)))\n",
    "print(\"mean_absolute_percentage_error :\" + str(mean_absolute_percentage_error(y_test, y_predict)))\n",
    "print(\"median_absolute_percentage_error :\" + str(median_absolute_percentage_error(y_test, y_predict)))\n",
    "# Model 2: Decision tree (Much better)\n",
    "# Testing max_depth, around 6-8 will be the best\n",
    "\n",
    "'''\n",
    "for i in range(3, 100):\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=i)\n",
    "    regr_1.fit(X_train, y_train)\n",
    "    y_predict_1 = regr_1.predict(X_test)\n",
    "    print(\"Decision tree with depth\" + str(i))\n",
    "    print(r2_score(y_test, y_predict_1))\n",
    "    print(mean_absolute_error(y_test, y_predict_1))\n",
    "    print(mean_absolute_percentage_error(y_test, y_predict_1))\n",
    "'''\n",
    "\n",
    "regr_1 = DecisionTreeRegressor(max_depth=6)\n",
    "regr_1.fit(X_train, y_train)\n",
    "y_predict_1 = regr_1.predict(X_test)\n",
    "print(\"Decision tree with depth 6\")\n",
    "print(\"r2_score :\" + str(r2_score(y_test, y_predict_1)))\n",
    "print(\"mean_absolute_error :\" + str(mean_absolute_error(y_test, y_predict_1)))\n",
    "print(\"median_absolute_error :\" + str(median_absolute_error(y_test, y_predict_1)))\n",
    "print(\"mean_absolute_error :\" + str(mean_absolute_percentage_error(y_test, y_predict_1)))\n",
    "print(\"median_absolute_percentage_error :\" + str(median_absolute_percentage_error(y_test, y_predict_1)))\n",
    "'''\n",
    "# Model 3: Adaboost (Time-consuming)\n",
    "rng = np.random.RandomState(1)\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=50, random_state=rng)\n",
    "regr_2.fit(X_train, y_train)\n",
    "y_predict_2 = regr_2.predict(X_test)\n",
    "print(\"Decision tree with depth 4\")\n",
    "print(r2_score(y_test, y_predict_2))\n",
    "print(mean_absolute_error(y_test, y_predict_2))\n",
    "print(mean_absolute_percentage_error(y_test, y_predict_2))\n",
    "'''\n",
    "\n",
    "# Model 4: SVM (Time-consuming) (Best: Poly)\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "y_rbf = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "y_poly = svr_poly.fit(X_train, y_train).predict(X_test)\n",
    "print(\"RBF Kernel\")\n",
    "print(\"r2_score :\" + str(r2_score(y_test, y_rbf)))\n",
    "print(\"mean mean_absolute_error :\" + str(mean_absolute_error(y_test, y_rbf)))\n",
    "print(\"median_absolute_error :\" + str(median_absolute_error(y_test, y_rbf)))\n",
    "print(\"mean_absolute_percentage_error :\" + str(mean_absolute_percentage_error(y_test, y_rbf)))\n",
    "print(\"median_absolute_percentage_error :\" + str(median_absolute_percentage_error(y_test, y_rbf)))\n",
    "print(\"Poly Kernel\")\n",
    "print(\"r2_score :\" + str(r2_score(y_test, y_poly)))\n",
    "print(\"mean_absolute_error :\" + str(mean_absolute_error(y_test, y_poly)))\n",
    "print(\"median_absolute_error :\" + str(median_absolute_error(y_test, y_poly)))\n",
    "print(\"mean_absolute_error :\" + str(mean_absolute_percentage_error(y_test, y_poly)))\n",
    "print(\"median_absolute_percentage_error :\" + str(median_absolute_percentage_error(y_test, y_poly)))\n",
    "\n",
    "# Model 5: SGDRegressor\n",
    "clf = SGDRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict_sgd = clf.predict(X_test)\n",
    "print(\"SGDRegressor\")\n",
    "print(\"r2_score :\" + str(r2_score(y_test, y_predict_sgd)))\n",
    "print(\"mean_absolute_error :\" + str(mean_absolute_error(y_test, y_predict_sgd)))\n",
    "print(\"median_absolute_error :\" + str(median_absolute_error(y_test, y_predict_sgd)))\n",
    "print(\"mean_absolute_error :\" + str(mean_absolute_percentage_error(y_test, y_predict_sgd)))\n",
    "print(\"median_absolute_percentage_error :\" + str(median_absolute_percentage_error(y_test, y_predict_sgd)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result #\n",
    "\n",
    "After comparing different training model, the SVM with poly kernel performs the best (with a median_absolute_percentage_error around 17%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Prediction of NA_Sales : 0.0511291483581\n",
      "Actual of NA_Sales : 0.02\n",
      "Prediction of EU_Sales : 0.120475348514\n",
      "Actual of EU_Sales : 0.03\n",
      "Prediction of JP_Sales : 0.0197422274917\n",
      "Actual of JP_Sales : 0.0\n",
      "Prediction of Other_Sales : 0.0301439347881\n",
      "Actual of Other_Sales : 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def median_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = statistics.median(y_true), statistics.median(y_pred)\n",
    "    return abs((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "# Loading data\n",
    "csv_path = \"data\\Video_Games_Sales_as_at_22_Dec_2016.csv\"\n",
    "\n",
    "# Read csv\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# print(df.head())\n",
    "print(\"\\n\\n\\n\")\n",
    "# Use LabelEncoder to change category into number\n",
    "# Then use OneHotEncoder(For non-string)/get_dummies(For string) to add column to the dataframe\n",
    "# Test using platform column\n",
    "df2 = pd.get_dummies(df, columns=['Platform', 'Genre', 'Publisher', 'Developer'])\n",
    "# df2 = df\n",
    "# print(df2.head())\n",
    "\n",
    "# Drop row which has no critic score (NaN)\n",
    "df3 = df2[(df2.Critic_Score.notnull())]\n",
    "# print(df3.head())\n",
    "\n",
    "df3 = shuffle(df3)\n",
    "drop_column = ['Name', 'Year_of_Release', 'User_Score', 'User_Count']\n",
    "df4 = df3.drop(drop_column, 1)\n",
    "# print(df4.head())\n",
    "# print(df4.shape)\n",
    "feature_scaler = StandardScaler()\n",
    "df4[['Critic_Score']] = feature_scaler.fit_transform(df4[['Critic_Score']])\n",
    "\n",
    "\n",
    "# print(df4.head())\n",
    "\n",
    "# Predict the global sales\n",
    "\n",
    "\n",
    "region_list = ['NA_Sales','EU_Sales','JP_Sales','Other_Sales']\n",
    "\n",
    "for region in region_list:\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    y_scaler.fit(df4[[region]])\n",
    "    df4[[region]] = y_scaler.transform(df4[[region]])\n",
    "\n",
    "    y = df4[region]\n",
    "    X = df4.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales', 'Rating'], 1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n",
    "\n",
    "    svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "    svr_poly.fit(X_train, y_train)\n",
    "    predict = svr_poly.predict((X_test.values[0]).reshape(1,-1))\n",
    "\n",
    "    actual = y_scaler.inverse_transform(y_test.values[0].reshape(1,-1))[0][0]\n",
    "\n",
    "    predict = y_scaler.inverse_transform(predict)[0]\n",
    "\n",
    "\n",
    "    print(\"Prediction of \"+region+ \" : \" + str(predict))\n",
    "    print(\"Actual of \"+region+ \" : \" + str(actual))\n",
    "    # print(\"error :\" + str(np.abs((predict - actual)) * 100 / actual))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
